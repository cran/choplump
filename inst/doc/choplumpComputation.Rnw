%\documentclass{simauth}
\documentclass{article}[12pt]
%\documentclass{biometrics}[12pt]
%\topmargin -.65in
%\textheight 9in
\topmargin -.5in
\textheight 8.25in
\oddsidemargin 0in
\evensidemargin 0in
\textwidth 6.5in
\parindent 3em
%\pagestyle{empty}

\usepackage{epsfig}


\newcommand{\pname}{\texttt{hbim}}


% \VignetteIndexEntry{Computational Details for Choplump Test}
% \VignetteKeyword{mathematics}
% \VignetteKeyword{htest}

<<PreliminaryCalculations,echo=FALSE,hide=TRUE>>=
#source("H:\\main\\methods\\choplump\\r\\chop.functions.R")
library(choplump)
SEED<-1:200
@

\begin{document}
\baselineskip 12pt




{\Large Computational Details for Choplump test: Test Motivated in ``Chop-lump Tests for
Vaccine Trials''}

by Dean A. Follmann, Michael P. Fay, and Michael A. Proschan \\
\today



%\addtocounter{section}{-1}
%\renewcommand{\thesection}{\Alph{section}}


%\section{Computational Details }


\section{General Chop-Lump Test}

Suppose $n_0$ and $n_1$ subjects are randomized to control and 
vaccine respectively. Here we allow $n_0 \neq n_1$, which causes 
some notational complexity, although the chopping function simply  
removes zeros from both groups in approximately the same proportion 
within each group such that one group has no zeros.

Let $m_0$ and $m_1$ denote the number of positive responses in the control and vaccine group 
repectively.  Let $k_i=n_i-m_i$, $N=n_0+n_1$, $M=m_0+m_1$, 
and $K=k_0+k_1$. Let the responses be represented by the vector, ${\bf 
W} =\left[ W_{1},W_{2},\ldots,W_{N} \right]$, where ${\bf W}$ are the responses of all $N$ subjects
 and $K$ of those responses are $0$. Let the treatment randomization assignment be denoted by the vector, 
 ${\bf Z} = \{ Z_{1}, \ldots,Z_{N} \}$, where $Z_i=0$ for subjects randomized to control and $Z_i=1$ for subjects 
 randomized to vaccine.  We order the indices by 
$W_i$ first then by $Z_i$ within tied $W_i$ values, so that  
$Z_1,\ldots,Z_{k_0}$ are zeros and $Z_{k_0+1},\ldots, Z_{K}$ are 
ones.
Let ${\bf W}_{a}$ and ${\bf Z}_{a}$ be the last $a$ values of ${\bf 
W}$ and ${\bf Z}$, respectively.
Let ${\bf 0}_{a}$ and ${\bf 1}_{a}$ be vectors of zero or one of 
length $a$, where $a=0$ denotes no vector (e.g., $\left[ {\bf 0}_3, 
{\bf 1}_0 \right]$ is a $3 \times 1$ vector of 0's).
Let $C({\bf W}, {\bf Z})$ be the chopping function which creates the 
``chopped'' data set, specifically,
\begin{eqnarray*}
C({\bf W}, {\bf Z}) =
%\left\{ \begin{array}{ll}
\left( {\bf W}_{M+a+b},\left[ {\bf 0}_{a}, {\bf 1}_{b}, {\bf Z}_{M} 
\right]  \right),
%\end{array} \right.
\end{eqnarray*}
where
\begin{eqnarray*}
\mbox{ if $\frac{m_0}{n_0} \geq \frac{m_1}{n_1}$ } & & \mbox{ then 
$a=0$ and $b=k_1 - \lfloor \frac{ n_1 k_0}{n_0} \rfloor $} \\
 &\mbox{and} & \\
 \mbox{ if $\frac{m_0}{n_0} < \frac{m_1}{n_1}$ } & & \mbox{ then 
$a=k_0 - \lfloor \frac{ n_0 k_1}{n_1}\rfloor $ and $b=0$} \\
\end{eqnarray*}
and $\lfloor x \rfloor$ is the largest integer less than or equal to 
$x$.

In the usual permutation test, we define a test statistic $T$ which 
is a function of ${\bf W}$ and ${\bf Z}$.  Let $T_0$ be the test 
statistic evaluated at the original data, and $T_j$ be the test 
statistic evaluated at the $j$th permutation of
the values of ${\bf Z}$.
If lower values of the test statistic are more extreme, then a 
one-sided p-value is
\begin{eqnarray}
p-value = \frac{\sum_{j=1}^{N!} I\left\{ T_j \leq T_0 \right\}  
}{N!} \label{eq:pvalue}
\end{eqnarray}
where  $I(a)=1$ if $a$ is true and $0$ otherwise.
A chop-lump test is simply a permutation test where the test 
statistic is of the form,
$T_{CL}({\bf W},{\bf Z}) = T \left\{C \left( {\bf W},{\bf Z} \right)  
\right\}$.

\section{Computational Issues: Exact Tests}

In this section, we describe exact
computation for any two-sample permutation test.
There are computationally better ways to calculate the p-value than 
equation~\ref{eq:pvalue}. First, we we need not enumerate all $N!$ 
permutations of ${\bf Z}$, since there are only $\left( 
\begin{array}{c}  N \\ n_1 \end{array} \right)$ unique permutations 
of ${\bf Z}$, and each has exactly $n_0!n_1!$ permutations which 
correspond to the same permuted ${\bf Z}$.
We can obtain similar computational savings by partitioning the 
$\left( \begin{array}{c}  N \\ n_1 \end{array} \right)$ unique 
permutations into sets with equal numbers of zero responses in the 
vaccine group. One can think of this partition as being derived from 
the hypergeometric
distribution where we are sampling zeros in the vaccine group. The 
partition can be written as
\begin{eqnarray}
\left( \begin{array}{c}  N \\ n_1  \end{array} \right) = 
\sum_{h=\max(0,n_1-M)}^{\min(n_1,K)}
\left( \begin{array}{c}  K \\ h  \end{array} \right)\left( 
\begin{array}{c}  M \\ n_1 - h  \end{array} \right)
\label{eq:partition}
\end{eqnarray}
On the right-hand-side of  equation~\ref{eq:partition} the first 
term in the sum represents the number of ways to permute the indices 
of the zero responses, while the second term represents the number 
of ways to permute the nonzero
responses.  Let $Q_h$ be the proportion of the permutation test 
statistics less than or equal to the observed test statistic
among permutations with $h$ zeros in the vaccine group. 
Specifically,
\begin{eqnarray}
Q_h & = & \frac{ \sum_{j \in \Omega_h} I \left[ T_j \leq T_0 \right] 
}{ \left( \begin{array}{c}  M \\ n_1 - h  \end{array} \right) } 
\label{eq:Qh}
\end{eqnarray}
where $\Omega_h$ is the set of unique permutations of ${\bf Z}_{M}$  
that induce $h$ zeros in the vaccine group. In other words, 
$\Omega_h$ does not include two different permutations of ${\bf Z}$ 
if they only differ within the first $K=N-M$ elements, since those 
elements are all equal to zero.

The standard calculation groups the $N!$ permutations into  $\left( 
\begin{array}{c}  N \\ n_1 \end{array} \right)$ sets of unique 
permutations of ${\bf Z}$, and each set has the same number of 
members. In the case of equation~\ref{eq:partition}, each group with 
$h$ zeros in the vaccine group does not have the same number of 
members. The one-sided p-value is a weighted average of the $Q_h$ 
values:
\begin{eqnarray}
p-value  & = &  \sum_{h=\max(0,n_1-M)}^{\min(n_1,K)}  Pr[\mbox{ a 
permutation has $h$ zeros in the vaccine group} ] Q_h  \nonumber \\
 & = &  \sum_{h=\max(0,n_1-M)}^{\min(n_1,K)}  \left\{ \frac{
\left( \begin{array}{c}  K \\ h  \end{array} \right)
\left( \begin{array}{c}  M \\ n_1 - h  \end{array} \right) }{
\left( \begin{array}{c}  N \\ n_1  \end{array} \right) } \right\} 
Q_h  \nonumber \\
& = &  \sum_{h=\max(0,n_1-M)}^{\min(n_1,K)}  f(h ; K,M,n_1) Q_h 
\label{eq:sumQh}
\end{eqnarray}
where $f(h;K,M,n_1)$ is the implicitly defined probability mass 
function of the hypergeometric distribution.

\section{Computational Issues: Approximations for $Q_h$}

\subsection{Difference in Means Statistics on Scores}

The key to the approximation is state $Q_h$ in a form such that we 
can use the
permutational central limit theorem (PCLT), which we give informally 
(see Sen [1985] for formal statement).
\begin{description}
\item[PCLT:] {\it Consider a permutation where the test statistic is 
of the form $T_{\ell}({\bf S},{\bf R}) = \sum S_i R_i $, and where 
both of the $N \times 1$ vectors of constants,  ${\bf S}$ and ${\bf 
R}$, meet some regularity conditions as $N$ gets large. Under the 
assumption that each permutation of ${\bf R}$ is equally likely,
\begin{eqnarray}
(N-1)^{-1/2} \frac{ T_{\ell}({\bf S},{\bf R})  - N  \bar{S} 
\bar{R}}{  \hat{\sigma}_S \hat{\sigma}_R} \dot{\sim} N(0,1) 
\label{eq:pclt}
\end{eqnarray}
where $\bar{R},\bar{S}, \hat{\sigma}_R$ and $\hat{\sigma}_S$ are 
sample means and standard deviations and $\dot{\sim}$ denotes 
approximately distributed for large $N$.}
\end{description}

Before we consider chop-lump tests, we first consider a simple test 
statistic, representing the standardized difference in means of a 
set of scores $S_1,\ldots,S_N$,
\begin{eqnarray*}
T_{DiM}({\bf S},{\bf Z}) =
 \frac{ \left( \sum S_i Z_i - n_1 \bar{S} \right)   }{ \sqrt{V} }
\end{eqnarray*}
where all unmarked summations go from $i=1$ to $N$, and $V=(N-1) 
\hat{\sigma}_S^2 \hat{\sigma}_Z^2$, and as above $\hat{\sigma}_S^2$ 
and $\hat{\sigma}_Z^2=(N-1)^{-1} \sum (Z_i - \bar{Z})^2 = \frac{n_0 
n_1}{N(N-1)}$ are sample variances of the values of ${\bf S}$ and 
${\bf Z}$. The permutation t-test results when $S_i=W_i$ and the 
Wilcoxon rank sum test results when $S_i=rank(W_i)$ (i.e., in the 
earlier notation, the permutation t-test has $T({\bf W},{\bf 
Z})=T_{DiM}({\bf W},{\bf Z})$, while the Wilcoxon rank sum test has 
$T({\bf W},{\bf Z}) = T_{DiM}( rank({\bf W}), {\bf Z})$).  Since 
within the permutations of $Q_h$ (see equation~\ref{eq:Qh}) we only 
permute within the last $M$ values of ${\bf Z}$, we want to
write $T_{DiM}({\bf S},{\bf Z}) = a_h + b_h T_{\ell}({\bf S}_M,{\bf 
Z}_M)$, where $a_h$ and $b_h$ are constant throughout the 
permutations in  $\Omega_h$.
If we let $S_i=S_0$ for $i \leq K$ (i.e., scores when $W_i=0$) then 
we get
\begin{eqnarray*}
a_h & = & \frac{ h S_0 - n_1 \bar{S} }{ \sqrt{V}}  \\
& \mbox{and} & \\
b_h & = & \frac{ 1 }{\sqrt{V}}
\end{eqnarray*}
Thus, within the permutations in $\Omega_h$,
\begin{eqnarray*}
& & T_{DiM} ({\bf S}, {\bf Z}) \leq t   \\
 & \Rightarrow & T_{\ell}({\bf S}_M, {\bf Z}_M) \leq \frac{ t- a_h 
}{b_h} = t \sqrt{V} -hS_0 + n_1 \bar{S} \\
  & \Rightarrow & \frac{ T_{\ell}({\bf S}_M, {\bf Z}_M) - M 
\bar{S}_M \bar{Z}_M }{\sqrt{V_M}  } \leq \frac{ t \sqrt{V} -hS_0 + 
n_1 \bar{S} - M \bar{S}_M \bar{Z}_M  }{ \sqrt{V_M} }
\end{eqnarray*}
where $V_M = (M-1) \hat{\sigma}_{S_{M}}^2 \hat{\sigma}_{Z_M}^2$.
Then substituting $\bar{Z}_M=\frac{n_1-h}{M}$ and using the PCLT we 
approximate $Q_h$ for $T_{DiM}$ with
\begin{eqnarray}
\hat{Q}_{h}^{(DiM)}  = \Phi\left\{ T_0 \sqrt{\frac{V}{V_M}} +C(h) 
\right\}, \label{eq:Qhdim}
\end{eqnarray}
where $\Phi()$ is the standard normal cumulative distribution, and
\begin{eqnarray*}
C(h)  = \frac{ -hS_0 + n_1 \bar{S} - (n_1-h) \bar{S}_M  }{  
\sqrt{V_M} }
\end{eqnarray*}

\subsection{Chop-Lump Statistics}


Now consider the chop-lump versions of $T_{DiM}$, i.e.,
$T_{CL}({\bf S},{\bf Z}) = T_{DiM}\left\{ C({\bf S},{\bf Z}) 
\right\}$. There is one slight complication with the Wilcoxon rank 
sum chop-lump test; the rankings are calculated after the chop, so 
that the scores will change for different permutations. To minimize 
this problem, we rank only the non-zero values of ${\bf W}$, (i.e., 
${\bf X}$), then we define $S_0$, the score that goes with $W_i=0$, 
according to how many total zeros in the chopped data.
Specifically, if there are $k$ total zeros in the chopped data set, 
then let $S_0^{(k)} = -(k-1)/2$. The resulting scores give 
equivalent tests to the usual ranks, since they are just shifted 
ranks, $S_i= R_i - k$.

Suppose that when there are $h$ zeros in the vaccine group in a 
permutation, this induces
%$k_1(h)$ and $k_0(h)$
$h^*$ zeros
in the vaccine group of
%and control groups, respectively
the chopped data set, where
\begin{eqnarray*}
h^* & = & \left\{
\begin{array}{ll}
h - \lfloor \frac{ n_1 (K-h)}{n_0} \rfloor & \mbox{ if 
$\frac{M-n_1+h}{n_0} \geq \frac{n_1-h}{n_1}$ } \\
0 &  \mbox{ if $\frac{M-n_1+h}{n_0} < \frac{n_1-h}{n_1}$ }
\end{array}
\right.
\end{eqnarray*}
Then we proceed similar to as above.
Write $T_{CL}({\bf S},{\bf Z}) = a_{h^*} + b_{h^*} T_{\ell}({\bf 
S}_M,{\bf Z}_M)$, where $a_{h^*}$ and $b_{h^*}$ are constant 
throughout the permutations in  $\Omega_h$. Let a superscript 
asterisk denote the sample sizes in the chopped data set (e.g., 
$K^*$ is the total number of zeros in the chopped data, so that 
$K^*=h^*$ if $h^*>0$ and $K^* = K$ if $h^*=0$). Further let $\sum^* 
= \sum_{i=N-N^*+1}^{N}$.
\begin{eqnarray*}
T_{DiM}^{(h^*)}({\bf S}_{N^*},{\bf Z}_{N^*}) =  \frac{  \sum^* S_i 
Z_i - n_1^* \bar{S}_{N^*} }{\sqrt{V_{N^*}}  }.
\end{eqnarray*}

Now rewrite $T_{DiM}^{(h^*)}({\bf S}_{N^*},{\bf Z}_{N^*})$ as 
$a_{h^*} + b_{h^*} T_{\ell} ({\bf S}_{M},{\bf Z}_{M})$, where
\begin{eqnarray*}
a_{h^*} & = & \frac{ h^* S_0^{(K^*)} - n_1^* \bar{S}_{N^*} }{ 
\sqrt{V_{N^*}} } \\
& \mbox{and} & \\
b_{h^*} & = & \frac{ 1 }{\sqrt{V_{N^*}}}
\end{eqnarray*}

Again using the PCLT we approximate $Q_h$ for $T_{DiM}$ with
\begin{eqnarray*}
\hat{Q}_{h}^{(CL)} = \Phi\left(   \frac{ T_0  \sqrt{V_{N^*}} -h^* 
S_0^{(K^*)} + n_1^* \bar{S}_{N^*} - (n_1^*-h^*) \bar{S}_M  }{  
\sqrt{V_M} } \right).
\end{eqnarray*}




\end{document}



\subsection{Special Case: Wilcoxon Rank Sum Test}

Consider the Wilcoxon rank sum test. We write an equivalent form of 
the test, by letting the scores be the ranks minus the total number 
of zeros. We use this form of the test, because later when we change 
the number of zeros, the scores for the non-zero values of ${\bf W}$ 
will not change; those scores will always equal $S_i = R_i - k$, 
where $k$ is the number of zeros and $R_i$ is the rank within the 
non-zero values of ${\bf W}$ (i.e., the rank of $X_i$ among the 
${\bf X}$).
Then the score for the zero values is $S_0^{(K)} = (1-K)/2$. In this 
form we get the following (assuming no ties among the ${\bf X}$):
\begin{eqnarray*}
S_0 & = & \frac{1-K}{2} = \frac{ 1 -N+M}{2} \\
\bar{S} & = & \frac{N+1}{2} - K = \frac{N + 1 - 2(N-M) }{2} = 
\frac{1-N}{2} + M \\
\bar{S}_M & = & \frac{M+1}{2} \\
V & = & \frac{n_1 n_0 (N+1) }{12} - \frac{n_1 n_0 (K^3 - K) }{ 
12N(N-1) } \\
V_M & = & \frac{m_1 m_0 (M+1)}{12}
\end{eqnarray*}
In this case we get
\begin{eqnarray*}
\sqrt{V_M} C(h) & = &
-hS_0 + n_1 \bar{S} - (n_1-h) \bar{S}_M  \\
 & = & -h \frac{ 1 -N+M}{2}
+ n_1 \left( \frac{1-N}{2} + M \right)- (n_1-h) \frac{M+1}{2} \\
& = & \frac{1}{2} \left\{ Nh - n_1 (N-M) \right\}
\end{eqnarray*}


\subsection{Special Case of Wilcoxon rank sum: when $n_1=n_0$}

When $h=n_1-m_1$ and $n_1=n_0 \equiv n$ then
\begin{eqnarray*}
\sqrt{V_M} C(h) & = & \frac{n}{2} \left\{ m_0 -m_1 \right\}
\end{eqnarray*}
This result agrees with Mike Proschan's equation~3, except the sign 
is changed because he used $S_i= -W_i$.

Let
\begin{eqnarray*}
\lim_{n \rightarrow \infty} \frac{ m_0}{n}  = p_0 \\
\lim_{n \rightarrow \infty} \frac{ m_1}{n} =  p_1 
%\label{eq:p.assumption}
\end{eqnarray*}
Let $\bar{p}=(p_0+p_1)/2$ so that $\lim_{n \rightarrow \infty} 
\frac{M}{N}=\bar{p}$ and  $\lim_{n \rightarrow \infty} 
\frac{K}{N}=1-\bar{p}$.
Then in the limit as $n$ go to infinity, we get (when $n_1=n_0=n$ 
and $h=n_1-m_1$)
\begin{eqnarray*}
\lim_{n \rightarrow \infty} \frac{V}{V_M} & = & \lim_{n \rightarrow 
\infty} \frac{ n_1 n_0 (N+1) }{m_1 m_0 (M+1) } - \lim_{n \rightarrow 
\infty} \frac{n_1 n_0 (K^3 - K) }{ m_1 m_0 (M+1) N(N-1) }  \\
 & = &  \frac{ 1 }{p_1 p_0 \bar{p} } - \frac{ (1-\bar{p})^3 }{ p_1 
p_0 \bar{p}  }  \\
\lim_{n \rightarrow \infty} C(h) & = &
\lim_{n \rightarrow \infty} \frac{n(m_0-m_1)}{2 \sqrt{V_M}} \\
 & = & \lim_{n \rightarrow \infty} \frac{\sqrt{3} n(m_0-m_1) }{ 
\sqrt{m_1 m_0 (M+1) }} \\
& = & \lim_{n \rightarrow \infty} 
\frac{\sqrt{3}(\frac{m_0}{n}-\frac{m_1}{n}) }{ \sqrt{\frac{ m_1 m_0 
(M+1)}{n^4} }} \\
& \stackrel{?}{=} &  \lim_{n \rightarrow \infty} 
\frac{\sqrt{3n}(p_0-p_1) }{ \sqrt{ p_1 p_0 \bar{p}  }}
\end{eqnarray*}
By the last expression, if $p_0 \neq p_1$ then $\lim_{n \rightarrow 
\infty} \hat{Q}_{h}^{(DiM)} =1$.

Now consider the interesting case when $p_0=p_1=\bar{p} \equiv p$. 
Then
\begin{eqnarray*}
\lim_{n \rightarrow \infty} \frac{V}{V_M} & = &  \frac{ 1 }{p^3} - 
\frac{ (1-p)^3 }{ p^3  }  \\
\lim_{n \rightarrow \infty} C(h) & = &
\lim_{n \rightarrow \infty} \frac{\sqrt{3} n(m_0-m_1) }{ \sqrt{m_1 
m_0 (M+1) }} \\
& = &
\lim_{n \rightarrow \infty} \frac{\sqrt{3} n \sqrt{2 n p(1-p)} 
z_{prop} }{ \sqrt{m_1 m_0 (M+1) }}
\stackrel{?}{=}  \frac{ \sqrt{6  (1-p)} z_{prop} }{p}
\end{eqnarray*}
where
\begin{eqnarray*}
z_{prop} & = & \frac{ m_0-m_1}{\sqrt{2np(1-p)}}
\end{eqnarray*}
Here I got an extra factor of $\sqrt{2}$ compared to Mike's 
results.



\subsection{Special Case: Permutation t-test}

The permutation t-test came be put in the form of a linear 
permutation test with scores equal to the observed values, i.e., 
$S_i=W_i$ (see e.g., Lehmann, 1986, p. 203). Thus,
\begin{eqnarray*}
S_0 & = & 0 \\
\bar{S} & = & N^{-1} \sum_{i=1}^{N} W_i = \frac{M}{N} \bar{X} \\
\bar{S}_M & = & \bar{X} \\
\hat{\sigma}_{X}^2 & = & \hat{\sigma}_{S_M}^2 = \frac{1}{M-1} 
\sum_{i=K+1}^{K+M} (X_i - \bar{X})^2 \\
\hat{\sigma}_{S}^2 & = & \frac{1}{N-1} \sum_{i=1}^{N} (S_i - 
\bar{S})^2 \\
& = & \frac{1}{N-1} \left\{ K \left(0- \frac{M}{N} \bar{X}\right)^2  
+   \sum_{i=K+1}^{N} (X_i - \frac{M}{N} \bar{X} )^2  \right\} \\
& = & \frac{1}{N-1} \left\{ \frac{K M^2 \bar{X}^2}{N^2}   +   
\sum_{i=K+1}^{N} (X_i - \bar{X} + \frac{K}{N} \bar{X} )^2  \right\} 
\\
& = & \frac{1}{N-1} \left\{ \frac{K M^2 \bar{X}^2}{N^2}   +   
\sum_{i=K+1}^{N} \left[ (X_i - \bar{X})^2  + 2 \frac{K}{N} 
\bar{X}(X_i - \bar{X})   +  \frac{K^2 \bar{X}^2}{N^2} \right]  
\right\} \\
& = & \frac{1}{N-1} \left\{ \frac{K M(M+K) \bar{X}^2}{N^2}   +   
\sum_{i=K+1}^{N} \left[ (X_i - \bar{X})^2 \right]  \right\} \\
& = & \frac{K M \bar{X}^2}{(N-1) N}   +  \frac{M-1}{N-1}  
\hat{\sigma}^2_X  \\
\hat{\sigma}^2_Z & = & \frac{ n_0 n_1}{(N-1)N} \\
\hat{\sigma}^2_{Z_M} & = & \frac{ m_0 m_1}{(M-1)M}  \\
V & = & (N-1) \hat{\sigma}_Z^2 \hat{\sigma}_S^2 = \frac{n_0 n_1}{N} 
\left\{ \frac{K M \bar{X}^2}{(N-1) N}   +  \frac{M-1}{N-1}  
\hat{\sigma}^2_X  \right\}
\\
V_M & = & (M-1) \hat{\sigma}_{Z_M}^2 \hat{\sigma}_{S_M}^2 =
\frac{m_0 m_1}{M}  \hat{\sigma}_{X}^2
\end{eqnarray*}
Further, the expression in equation~\ref{eq:Qhdim}:
\begin{eqnarray*}
\sqrt{V_M} C(h) & = & -hS_0 + n_1 \bar{S} - (n_1-h) \bar{S}_M \\
  & = &
\frac{ n_1 M \bar{X} }{N} -(n_1-h) \bar{X} \\
& = & \bar{X} \left( h - \frac{ K n_1 }{N} \right)
\end{eqnarray*}

Consider the limits. Using the notation as before, let
$\lim_{n \rightarrow \infty} m_0/n_0=p_0$ and
$\lim_{n \rightarrow \infty} m_1/n_1=p_1$ and
$\lim_{n \rightarrow \infty} M/N=\bar{p}$.
Then
\begin{eqnarray*}
\lim_{n \rightarrow \infty} \frac{V}{V_M} & = & \lim_{n \rightarrow 
\infty} \frac{n_0 n_1 K M^2 \bar{X}^2 }{m_0 m_1 N^2 (N-1) 
\hat{\sigma}^2_X } + \lim_{n \rightarrow \infty} \frac{ n_0 n_1 
(M-1) M }{m_0 m_1 (N-1) N } \\
 & \stackrel{?}{=} & \lim_{n \rightarrow \infty} \frac{ (1-\bar{p}) 
\bar{p}^2 \bar{X}^2 }{p_0 p_1  \hat{\sigma}^2_X } +  \frac{  
\bar{p}^2 }{p_0 p_1  } \\
 \lim_{n \rightarrow \infty} C(h) & = &
  \lim_{n \rightarrow \infty}
 \bar{X} \left( \frac{h N- K n_1 }{N \sqrt{V_M}} \right) \\
& = &   \lim_{n \rightarrow \infty} \frac{\bar{X}}{\hat{\sigma}_X} 
\frac{(h N - K n_1) \sqrt{M} }{N \sqrt{m_0 m_1} } \\
 & = &   \lim_{n \rightarrow \infty} \frac{\bar{X}}{\hat{\sigma}_X} 
\frac{\frac{h N}{\sqrt{n_0n_1}} - \frac{K n_1}{\sqrt{n_0n_1}} 
\sqrt{\bar{p}} }{\sqrt{N} \sqrt{\frac{m_0 m_1}{n_0n_1}} }
\end{eqnarray*}
Now if $n_0=n_1$ the last expression simplifies to
\begin{eqnarray*}
 \lim_{n \rightarrow \infty}
 \bar{X} \left( \frac{h N- K n_1 }{N \sqrt{V_M}} \right)
& = &    \lim_{n \rightarrow \infty} \frac{\bar{X}}{\hat{\sigma}_X} 
\frac{2 h  - \sqrt{K (1-\bar{p}) \bar{p}} }{ \sqrt{p_0 p_1 }}
\end{eqnarray*}
and
\begin{eqnarray*}
 \lim_{n \rightarrow \infty} \hat{Q}_{h}^{(DiM)} & \stackrel{?}{=} 
&
 \Phi \left( T_0 \sqrt{  \frac{  \bar{p}^2 }{p_0 p_1  } +  \lim_{n 
\rightarrow \infty} \frac{ (1-\bar{p}) \bar{p}^2 \bar{X}^2 }{p_0 p_1  
\hat{\sigma}^2_X }  } +
 \lim_{n \rightarrow \infty} \frac{\bar{X}}{\hat{\sigma}_X} \frac{2 
h  - \sqrt{K (1-\bar{p}) \bar{p}} }{ \sqrt{p_0 p_1 }}
\right)
\end{eqnarray*}




\subsection*{Usual t-test Form}

{\bf Leave this part out?}

Note that if we can write our test statistic $T({\bf W},{\bf Z})$ as  
$g(T_{\ell}({\bf W},{\bf Z}))$ for a monotonically increasing 
function $g$, then we can use similar methods, except the inverse 
function needed, $g^{-1}()$, may be much more complicated. For 
example, when $T()$ is the usual two-sample t-test, then
\begin{eqnarray*}
g(t; {\bf W},n_1) = \frac{ \left( t - n_1 \bar{W} \right) \sqrt{N-2} 
}{\sqrt{\frac{N}{n_0 n_1}  \left\{ \sum (W_i - \bar{W})^2 \right\} - 
(t-n_1 \bar{W})^2 } },
\end{eqnarray*}
 (see e.g., Lehmann, 1986, p. 203).




\begin{eqnarray*}
\mbox{ if $\frac{M-n_1+h}{n_0} \geq \frac{n_1-h}{n_1}$ } & & \mbox{ 
then $k_0(h)=0$ and $k_1(h)=k_1 - \lfloor \frac{ n_1 k_0}{n_0} 
\rfloor $} \\
 &\mbox{and} & \\
 \mbox{ if $\frac{M-n_1+h}{n_0} < \frac{n_1-h}{n_1}$ } & & \mbox{ 
then $k_0(h)=k_0 - \lfloor \frac{ n_0 k_1}{n_1}\rfloor $ and 
$k_1(h)=0$} \\
\end{eqnarray*}





Let the cumulative distribution function (cdf) of the permutation 
be
\begin{eqnarray*}
F_{perm}(t; {\bf S}, n_1) & = & Pr[ T_j^* \leq t | \mbox{ All $N!$ 
permutations equally likely}, T^*({\bf S}, {\bf Z}) = \sum Z_i S_i, 
\sum Z_i = n_1 ].
\end{eqnarray*}
In this notation, $F_{perm}(T_0^*; {\bf S},n_1)$ is the p-value of 
the permutation test. There are many algorithms for calculating 
$F_{Perm}(t; {\bf S},n_1)$, and at the minimum the algorithm should 
not require more than $\left( \begin{array}{c}  N \\ n_1  
\end{array} \right)$  calculations of $T$ by the permuted data.
Note that if we can write our test statistic $T({\bf W},{\bf Z})$ as  
$g(T^*({\bf W},{\bf Z}))$ for a monotonically increasing function 
$g$, then the p-value of the permutation test based on $T()$ is 
$F_{perm}(\sum Z_i W_i; {\bf W}, n_1)$. For example, when $T()$ is 
the usual two-sample t-test, then
\begin{eqnarray*}
g(t; {\bf W},n_1) = \frac{ \left( t - n_1 \bar{W} \right) \sqrt{N-2} 
}{\sqrt{\frac{N}{n_0 n_1}  \left\{ \sum (W_i - \bar{W})^2 \right\} - 
(t-n_1 \bar{W})^2 } },
\end{eqnarray*}
where $\bar{W}=N^{-1} \sum W_i$
and the associated permutation p-value is $F_{Perm}(\sum Z_i W_i; 
{\bf W},n_1)$ (see e.g., Lehmann, 1986, p. 203).
Notice that $g()$  depends on ${\bf W}$ and $n_1$ but not on ${\bf 
Z}$.




\section*{Approximate Calculation of $Q_h$ by PCLT}






The second basic simplification occurs with the two most common test 
statistics,
the difference in means statistic and test statistic associated with 
the Wilcoxon rank sum test.
Both these statistics can be put in the form,
\begin{eqnarray}
T({\bf Z},{\bf W}) = \sum_{i=1}^{N} Z_i S_i \label{eq:lpt}
\end{eqnarray}
where $S_i$ is some score which may depend on ${\bf W}$. For 
example, for the difference in means test
$S_i = \{ N (W_i - \bar{W} ) \}/(N_c n_1)$ and for the rank test 
$S_i=R_i$, the midrank of the $i$th observation among all $N$ 
observations (the midrank is just the usual rank used with ties, 
where the midrank of a tied value is equal to the average rank of 
the responses with the same value). We call test statistics in the 
form of equation~\ref{eq:lpt} linear permutation tests (LPT).
A simplifying property of the LPT is that the p-values of the tests 
do not change if you modify the score $S_i$ by multiplying or adding 
a constant that is unchanged through all permutations.  We can see 
this by inspection of equation~\ref{eq:pvalue}. Thus, the difference 
in means test can be equivalently written as equation~\ref{eq:lpt} 
with $S_i=W_i$.

To calculate the exact p-value for a two-sample LPT all we need are 
the set of scores, ${\bf S}=\{ S_1,\ldots, S_N\}$, the observated 
test statisic, $T_0$, and the number of $Z_i$ values equal to one, 
$n_1$. We write the p-value in terms of these three inputs as a 
cumulative distribution function (cdf) for the two-sample LPT 
permutation distribution,
\[
F_{Perm}(T_0 ; {\bf S}, n_1 ) = Pr[ T_j \leq T_0 | \mbox{ Each of 
$N!$ permutations equally likely}, T({\bf Z},{\bf W}) = \sum Z_i 
S_i, \sum Z_i = n_1 ]
\]
where $T_j$ is defined above. There are many algorithms for 
calculating $F_{Perm}(T_0; {\bf S},n_1)$, and at the minimum the 
algorithm should not require more than $\left( \begin{array}{c}  N 
\\ n_1  \end{array} \right)$  calculations of $T$ by the permuted 
data.
We will use this cdf with different input values in the next 
section.

\section{Exact Calculation of a LPT when there are Many Responses of 
One Value}

There is a reduction in enumeration for the LPT test when there are 
many responses with one value that is
similar to the first simplification discussed above.
We discuss the case where there are many zero responses, but the 
simplification could apply to a tied value equal to something else.
Start from the set of $\left( \begin{array}{c}  N \\ n_1  
\end{array} \right)$ unique permutations that ignore
different indices within vaccine group. Let $k=N-m$ be the total 
number of zero responses from both groups combined.
%,and simplarly let $k_v=n_1-m_v$ and $k_c=N_c-M_c$.
We can partition the  $\left( \begin{array}{c}  N \\ n_1  
\end{array} \right)$ unique permutations into sets with equal 
numbers of zero responses in the vaccine group. One can think of 
this partition as being derived from the hypergeometric
distribution where we are sampling zeros in the vaccine group. The 
partition can be written as
\begin{eqnarray}
\left( \begin{array}{c}  N \\ n_1  \end{array} \right) = 
\sum_{h=\max(0,n_1-m)}^{\min(n_1,k)}
\left( \begin{array}{c}  k \\ h  \end{array} \right)\left( 
\begin{array}{c}  m \\ n_1 - h  \end{array} \right)
\label{eq:partition}
\end{eqnarray}
On the right-hand-side of  equation~\ref{eq:partition} the first 
term in the sum represents the number of ways to permute the indices 
of the zero responses, while the second term represents the number 
of ways to permute the nonzero
responses.  Similar to the first simplification discussed in the 
previous section, we need not compute all the $\left( 
\begin{array}{c}  k \\ h  \end{array} \right)$ different 
permutations of the zero responses.
Let $Q_h$ be the proportion of the permutation test statistics less 
than or equal to the observed test statistic
among permutations with $h$ zeros in the vaccine group.
We can write $Q_h$ in terms of the $F_{Perm}$ function. Let $S_0 = 
S_i$ when $W_i=0$, then the sum of the zero scores in
the permuted vaccine group is $h S_0$ for all permutations with $h$ 
zeros in the vaccine group. Further, let ${\bf S}_{\bf X} = \{ 
S_1,\ldots S_{m_c},S_{N_c+1},\ldots,S_{N_c+m_v}\}$ be the set of 
scores
associated with the nonzero responses. Thus, using the second basic 
simplification mentioned in the previous section, we can write $Q_h$  
in terms of the $F_{Perm}$ function:
\begin{eqnarray*}
Q_h  = F_{Perm} ( T_0 - h S_0 ; {\bf S}_{\bf X}, n_1 -h).
\end{eqnarray*}
Note that the calculation of $Q_h$ only requires at most $\left( 
\begin{array}{c}  m \\ n_1 - h  \end{array} \right)$ calculations of 
the sum
of the $n_1 -h$ nonzero permuted responses in the vaccine group.
%The calculation of $Q_h$ can be done by complete enumeration of the   
$\left( \begin{array}{c}  m \\ m-h  \end{array} \right)$ ways of 
choosing $m-h$ %nonzero responses in the control group.
Then the one-sided p-value of a LPT with many zeros can be written 
as
\begin{eqnarray}
p-value  & = &  \sum_{h=\max(0,n_1-m)}^{\min(n_1,k)}  Pr[\mbox{ a 
permutation has $h$ zeros in the vaccine group} ] Q_h  \nonumber \\
 & = &  \sum_{h=\max(0,n_1-m)}^{\min(n_1,k)}  \left\{ \frac{
\left( \begin{array}{c}  k \\ h  \end{array} \right)
\left( \begin{array}{c}  m \\ n_1 - h  \end{array} \right) }{
\left( \begin{array}{c}  N \\ n_1  \end{array} \right) } \right\} 
Q_h  \nonumber \\
& = &  \sum_{h=\max(0,n_1-m)}^{\min(n_1,k)}  f(h ; k,m,n_1) Q_h 
\label{eq:sumQh}
\end{eqnarray}
where $f(h;k,m,n_1)$ is the implicitly defined pdf of the 
hypergeometric distribution.


\section{Chop-Lump Test}

Consider the scores for the difference in means test where 
$S_i=W_i$. In this case, the
the nonzero scores remain the same regardless of whether some zero 
scores are added or deleted from the set. To achieve a similar 
property for the ranks, we let $S_i$ be the rank of the nonzero 
values among all nonzero values, and let the score for the $k$ zero 
values be $S_0^{(k)} = -(k-1)/2$. For example, suppose there where 
10 zero values and 5 nonzero values with no ties. Then the usual 
midranks would be $(1+2+\cdots+10)/10 = 10*11/20 =5.5$ for the zero 
values and 11 through 15 for the nonzero values. The modification we 
propose is to simply subtract 10 from each rank, giving -4.5 for the 
zero  values  and 1 through 5 for the nonzero ones.

Let
$S_v^+ = T_0 - (n_1-m_v)S_0^{(k)}$ be the sum of the nonzero scores 
in the original vaccine group. Under the two scoring schemes of the 
previous paragraph, $S_v^+$ does not depend on the number of zero 
values in either treatment group.
Let $n_1 - m_v = k_v$. For the chop-lump test we try different 
values of $k_v$ depending on the value of $\theta_{11}$.
Let $k_v[\theta_{11}]$ be the number of zeros augmented to the 
nonzero vaccine group responses given $\theta_{11}$, and similarly 
let $k[\theta_{11}]$
be the total number of zeros augmented to both groups of responses.  
Finally, let
${\bf J}_k$ be a $k \times 1$ vector with all values equal to 
$S_0^{(k)}$.
Then the p-value for the exact chop-lump test is
\begin{eqnarray}
p-value & = &  \max_{\theta \in [0,\min(p_v,p_c)] } F_{Perm} ( 
S_v^{+} + k_v[\theta] S_0^{(k[\theta])} ; [ {\bf S}_{\bf X}, {\bf 
J}_{k[\theta]} ], m_v+k_v[\theta]).
\end{eqnarray}
In order to compare to the p-value for the usual LPT we consider the 
possible values of $k_v[\theta]$ and $k_c[\theta]$.

Recall, since $\hat{\theta}_{10}= \frac{m_v}{n_1} - \theta_{11}$ and 
$\hat{\theta}_{01} = \frac{m_c}{N_c} -\theta_{11}$, then
\begin{eqnarray*}
& & \frac{ k_v[\theta] }{ k_v[\theta] + m_v } = \frac{ 
\frac{m_c}{N_c} - \theta }{  \frac{m_c}{N_c} + \frac{m_v}{n_1} - 
\theta}  \\
& \Rightarrow &  k_v[\theta] \left(   \frac{m_c}{N_c} + 
\frac{m_v}{n_1} - \theta   \right) = \left( k_v[\theta] + m_v 
\right) \left( \frac{m_c}{N_c} - \theta \right)  \\
& \Rightarrow & \frac{ m_v k_v[\theta]}{n_1}   =  m_v  \left( 
\frac{m_c}{N_c} - \theta \right) \\
& \Rightarrow &  k_v[\theta]   =  n_1  \left( \frac{m_c}{N_c} - 
\theta \right) \\
\end{eqnarray*}
Similarly $k_c[\theta]   =  N_c  \left( \frac{m_v}{n_1} - \theta 
\right)$.

To easily see how this would be applied, we consider only the case 
where $N_c=n_1$.
Then $k_v[\theta]= m_c - n_1\theta$ and $k_c[\theta]=m_v - 
n_1\theta$ and $k[\theta]=k_v[\theta]+k_c[\theta]=m-2 n_1 \theta$. 
The possible values for the parameters are given in 
Table~\ref{tab:pos.theta}.
We can write p-value for the corresponding chop-lump test as
\begin{eqnarray*}
p-value & = &  \max_{i \in [\max(0,m_c-m_v),m_c] } F_{Perm} ( 
S_v^{+} + i S_0^{(2i+m_v-m_c)} ; [ {\bf S}_{\bf X}, {\bf 
J}_{2i+m_v-m_c} ], m_v+i).
\end{eqnarray*}



\begin{table}
\caption{Possible Values for $\theta_{11}$, $k_v[\theta_{11}]$, 
$k_c[\theta_{11}]$ and $k[\theta_{11}]$ when $n_1=N_c$ 
\label{tab:pos.theta} }
\begin{tabular}{cccc}
$\theta_{11}$ & $k_v[\theta_{11}]$ & $k_c[\theta_{11}]$ & 
$k[\theta_{11}]$ \\ \hline
$\frac{0}{n_1}$ & $m_c$ & $m_v$ & $m$ \\
$\frac{1}{n_1}$ & $m_c - 1$ & $m_v-1$ & $m-2$ \\
 & \vdots & & \vdots \\
$\frac{ \min(m_c,m_v) }{n_1}$ & $m_c - \min(m_c,m_v)$ & $m_v - 
\min(m_c,m_v)$ & $m-2 \min(m_c,m_v)$ \\ \hline
\end{tabular}
\end{table}



To compare this with the usual LPT, consider the LPT p-value 
rewritten in similar form (following equation~\ref{eq:sumQh}):
\begin{eqnarray}
 F_{Perm} ( S_v^+ + k_v S_0^{(k)}; &&  [{\bf S}_{\bf X}, {\bf J}_k], 
m_v+k_v)
 =    \nonumber  \\
&& \sum_{i=\max(-m_v,-k_c)}^{\min(k_v,m_c)}  f(k_v-i ; k,m,n_1) 
F_{Perm} ( S_v^+ + i S_0^{(k)} ; {\bf S}_{\bf X},m_v+ i).
\label{eq:lpt.usual}
\end{eqnarray}

When $n_1 = r N_c$ for $r \neq 1$,  then we have $k_v[\theta]=round( 
r m_c - r N_c \theta)$  and $k_c = round( m_v/r - N_c \theta)$,
where $round(x)$ rounds $x$ to the nearest integer.

\end{document}
